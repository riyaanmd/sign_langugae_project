# 🤟 Sign Speak

**Sign Speak** is an AI-powered real-time sign language recognition system that bridges communication between deaf and hearing individuals.  
It uses **computer vision** and **natural language processing (NLP)** to interpret gestures, process speech, and maintain contextual dialogue — enabling seamless two-way interaction through sign, text, and voice.

---

## 🌟 Features

- 🔹 **Real-Time Gesture Recognition** – Detects and interprets sign language using the **Gemini 1.5 Pro API** and **OpenCV**.  
- 🔹 **Speech-to-Text Conversion** – Converts voice input into text through **OpenAI Whisper API**.  
- 🔹 **Conversational AI** – Maintains contextual dialogue for natural and continuous interaction.  
- 🔹 **Text-to-Speech Feedback** – Delivers AI responses via voice using a TTS engine.  
- 🔹 **Streamlit Interface** – Simple, accessible, and user-friendly UI for smooth interaction.

---

## 🧠 System Architecture

The project integrates multiple AI modules working together:
1. **Gesture Recognition Module** – Captures and interprets live sign language gestures.  
2. **Voice Input Module** – Transcribes voice queries into text.  
3. **Conversational AI Module** – Generates context-aware, meaningful responses.  
4. **Text-to-Speech Module** – Converts text responses into natural-sounding audio.  

---

## 🧩 Technologies Used

| Component | Technology |
|------------|-------------|
| Programming Language | Python 3.x |
| User Interface | Streamlit |
| Computer Vision | OpenCV |
| Gesture Recognition | Gemini 1.5 Pro API |
| Speech Recognition | OpenAI Whisper API |
| Text-to-Speech | gTTS or equivalent |
| Frameworks | Deep Learning, NLP |

---

## ⚙️ Installation

1. **Clone the Repository**
   ```bash
   git clone https://github.com/yourusername/SignSpeak.git
   cd SignSpeak
